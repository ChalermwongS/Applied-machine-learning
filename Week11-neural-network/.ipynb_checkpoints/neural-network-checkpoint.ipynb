{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "9bf7a553-3a65-40b6-bfee-adf55b25b703",
    "_uuid": "931336d1-e65f-4a59-8231-4ed1eee589d1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Credit https://joelpendleton.github.io/XNOR-NeuralNet/\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def sigmoid(z):\n",
    "    return 1 / (1 + np.exp(-z))\n",
    "\n",
    "def sigmoid_derivative(z):\n",
    "    return sigmoid(z) * (1 - sigmoid(z))\n",
    "\n",
    "x = np.arange(-10., 10., 0.2)\n",
    "plt.plot(x,sigmoid(x), '-k', label=\"Sigmoid\")\n",
    "plt.legend(loc='upper left')\n",
    "plt.xlabel(\"z\")\n",
    "plt.ylabel(\"g(z)\")\n",
    "plt.show()\n",
    "\n",
    "X = np.array([[0,0],\n",
    "             [0,1],\n",
    "             [1,0],\n",
    "             [1,1]])\n",
    "\n",
    "y = np.array([[1],\n",
    "      [0],\n",
    "      [0],\n",
    "      [1]])\n",
    "\n",
    "\n",
    "class NeuralNetwork:\n",
    "\n",
    "    def __init__(self, X, y):\n",
    "        self.X = np.c_[np.ones((X.shape[0], 1)), X] #Training inputs\n",
    "        self.y = y # Training outputs\n",
    "        self.numberOfExamples = y.shape[0]  # Number of training examples\n",
    "        self.w_1 = (np.random.rand(2, 3) - 1) / 2  # Initialise weight matrix for layer 1\n",
    "        self.w_2 = (np.random.rand(1, 3) - 1) / 2  # Initialise weight matrix for layer 2\n",
    "\n",
    "        # Error in each layer\n",
    "        self.sigma2 = np.zeros((2,1))\n",
    "        self.sigma3 = np.zeros((3,1))\n",
    "\n",
    "        self.predictions = np.zeros((4,1))\n",
    "\n",
    "        # There is 2 input units in layer 1 and 2, and 1 output unit, excluding bias units.\n",
    "\n",
    "    def feedforward(self, x):\n",
    "\n",
    "        self.a_1 = x  # vector training example (layer 1 input)\n",
    "        self.z_2 = self.w_1 @ self.a_1\n",
    "        self.a_2 = sigmoid(self.z_2)\n",
    "        self.a_2 = np.vstack(([1], self.a_2))  # Add bias unit to a_2 for next layer computation\n",
    "        self.z_3 = self.w_2 @ self.a_2\n",
    "        self.a_3 = sigmoid(self.z_3) # Output\n",
    "        return self.a_3\n",
    "\n",
    "    def backprop(self):\n",
    "\n",
    "        # These are temporary variables used to compute self.D_1 and self.D_2\n",
    "        self.d_1 =  np.zeros(self.w_1.shape) \n",
    "        self.d_2 = np.zeros(self.w_2.shape)\n",
    "        \n",
    "        # These layers store the derivate of the cost with respect to the weights in each layer\n",
    "        self.D_1 = np.zeros(self.w_1.shape)\n",
    "        self.D_2 = np.zeros(self.w_2.shape)\n",
    "\n",
    "        for i in range(0,self.numberOfExamples):\n",
    "\n",
    "            self.feedforward(np.reshape(self.X[i, :], ((-1,1))))\n",
    "            self.predictions[i,0] = self.a_3\n",
    "            self.sigma3 = self.a_3 - y[i] #Calculate 'error' in layer 3\n",
    "            self.sigma2 = (self.w_2.T @ self.sigma3) * np.vstack(([0],sigmoid_derivative(self.z_2))) #Calculate 'error' in layer 2\n",
    "            '''We want the error for only 2 units, not for the bias unit. \n",
    "            However, in order to use the vectorised implementation we need the sigmoid derivative to be a 3 dimensional vector, so I added 0 as an element to the derivative.\n",
    "            This has no effect on the element-wise multiplication.'''\n",
    "            self.sigma2 = np.delete(self.sigma2, 0)  # Remove error associated to +1 bias unit as it has no error / output\n",
    "            self.sigma2 = np.reshape(self.sigma2, (-1, 1))\n",
    "\n",
    "            # Adjust the temporary variables used to compute gradient of J\n",
    "            self.d_2 += self.sigma3 @ (self.a_2.T)\n",
    "            self.d_1 += self.sigma2 @ (self.a_1.T)\n",
    "\n",
    "        # Partial derivatives of cost function\n",
    "        self.D_2 = (1/self.numberOfExamples) * self.d_2\n",
    "        self.D_1 = (1/self.numberOfExamples) * self.d_1\n",
    "\n",
    "    def probs(self, X): #Function to generate the probabilites based on matrix of inputs\n",
    "        \n",
    "        probabilities = np.zeros((X.shape[0], 1))\n",
    "        for i in range(0, X.shape[0]):\n",
    "            test = np.reshape(X[i,:], (-1,1))\n",
    "            test = np.vstack(([1], test))\n",
    "            probabilities[i, 0] = self.feedforward(test)\n",
    "        return probabilities\n",
    "\n",
    "# Neural network object\n",
    "nn = NeuralNetwork(X,y)\n",
    "\n",
    "alpha = 1  # Learning Rate\n",
    "\n",
    "for i in range(0, 2000): #Perform gradient descent\n",
    "    nn.backprop()\n",
    "\n",
    "    # Update weights\n",
    "    nn.w_1 += - alpha * nn.D_1\n",
    "    nn.w_2 += - alpha * nn.D_2\n",
    "\n",
    "\n",
    "xx, yy = np.mgrid[-0.1:1.1:0.1, -0.1:1.1:0.1]\n",
    "\n",
    "grid = np.c_[xx.ravel(), yy.ravel()]\n",
    "\n",
    "# Find the probabilities for each combination of features\n",
    "\n",
    "probs = nn.probs(grid).reshape(xx.shape)\n",
    "\n",
    "f, ax = plt.subplots(figsize=(12, 10))\n",
    "\n",
    "# Create contour lines for each set of probabilities\n",
    "\n",
    "contour = ax.contourf(xx, yy, probs, 25, cmap=\"RdBu\", vmin=0, vmax=1)\n",
    "\n",
    "plt.title(\"x$_1$ XNOR x$_2$\")\n",
    "ax_c = f.colorbar(contour)\n",
    "ax_c.set_label(\"$P(y = 1 | X)$\")\n",
    "ax_c.set_ticks([0, .25, .5, .75, 1])\n",
    "\n",
    "# Plot training examples on figure\n",
    "\n",
    "ax.scatter(X[:,0], X[:, 1], c=y[:,0], s=50,\n",
    "           cmap=\"RdBu\", vmin=-.2, vmax=1.2,\n",
    "           edgecolor=\"white\", linewidth=1)\n",
    "\n",
    "ax.set(aspect=\"equal\",\n",
    "       xlabel=\"x$_1$\", ylabel=\"x$_2$\")\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
