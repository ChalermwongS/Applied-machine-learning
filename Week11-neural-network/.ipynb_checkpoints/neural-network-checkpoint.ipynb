{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "_cell_guid": "9bf7a553-3a65-40b6-bfee-adf55b25b703",
    "_uuid": "931336d1-e65f-4a59-8231-4ed1eee589d1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000 train samples\n",
      "10000 test samples\n",
      "(60000,)\n",
      "Y train sample with one-hot =  [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      "(60000, 10)\n",
      "Number of train =  0\n",
      "a_1  (785, 1)\n",
      "z_2  [[108.94117755]\n",
      " [108.94117755]]\n",
      "a_2  [[1.]\n",
      " [1.]]\n",
      "a_2 with bias  [[1.]\n",
      " [1.]\n",
      " [1.]]\n",
      "z_3  [[3.]\n",
      " [3.]\n",
      " [3.]\n",
      " [3.]\n",
      " [3.]\n",
      " [3.]\n",
      " [3.]\n",
      " [3.]\n",
      " [3.]\n",
      " [3.]]\n",
      "a_3  [[0.95257413]\n",
      " [0.95257413]\n",
      " [0.95257413]\n",
      " [0.95257413]\n",
      " [0.95257413]\n",
      " [0.95257413]\n",
      " [0.95257413]\n",
      " [0.95257413]\n",
      " [0.95257413]\n",
      " [0.95257413]]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "could not broadcast input array from shape (10,1) into shape (10)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-c78940b9efcf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m#Perform gradient descent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 151\u001b[0;31m     \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackprop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m     \u001b[0;31m# Update weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-37-c78940b9efcf>\u001b[0m in \u001b[0;36mbackprop\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    112\u001b[0m             \u001b[0;31m#self.a_3 = self.a_3.reshape((self.a_3.shape[0],))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m             \u001b[0;31m#y[i] = np.reshape(y[i], (y[i].shape, 1))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m             \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msigma3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ma_3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m#Calculate 'error' in layer 3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"sigma3 \"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msigma3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: could not broadcast input array from shape (10,1) into shape (10)"
     ]
    }
   ],
   "source": [
    "#Credit https://joelpendleton.github.io/XNOR-NeuralNet/\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from keras.datasets import mnist\n",
    "import keras\n",
    "\n",
    "def sigmoid(z):\n",
    "    return 1 / (1 + np.exp(-z))\n",
    "\n",
    "def sigmoid_derivative(z):\n",
    "    return sigmoid(z) * (1 - sigmoid(z))\n",
    "\n",
    "'''x = np.arange(-10., 10., 0.2)\n",
    "plt.plot(x,sigmoid(x), '-k', label=\"Sigmoid\")\n",
    "plt.legend(loc='upper left')\n",
    "plt.xlabel(\"z\")\n",
    "plt.ylabel(\"g(z)\")\n",
    "plt.show()'''\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "print(x_train.shape)\n",
    "plt.subplot(221)\n",
    "plt.imshow(x_train[0], cmap=plt.get_cmap('gray'))\n",
    "plt.subplot(222)\n",
    "plt.imshow(x_train[1], cmap=plt.get_cmap('gray'))\n",
    "plt.subplot(223)\n",
    "plt.imshow(x_train[2], cmap=plt.get_cmap('gray'))\n",
    "plt.subplot(224)\n",
    "plt.imshow(x_train[3], cmap=plt.get_cmap('gray'))\n",
    "# show the plot\n",
    "plt.show()\n",
    "\n",
    "x_train = x_train.reshape(60000, 784)\n",
    "x_test = x_test.reshape(10000, 784)\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "print(y_train.shape)\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, 10)\n",
    "y_test = keras.utils.to_categorical(y_test, 10)\n",
    "print(\"Y train sample with one-hot = \",y_train[0])\n",
    "print(y_train.shape)\n",
    "\n",
    "'''X = np.array([[0,0],\n",
    "             [0,1],\n",
    "             [1,0],\n",
    "             [1,1]])\n",
    "\n",
    "y = np.array([[1],\n",
    "      [0],\n",
    "      [0],\n",
    "      [1]])'''\n",
    "\n",
    "X = x_train\n",
    "y = y_train\n",
    "\n",
    "class NeuralNetwork:\n",
    "\n",
    "    def __init__(self, X, y):\n",
    "        self.X = np.c_[np.ones((X.shape[0], 1)), X] #Training inputs, Is bias data here?\n",
    "        self.y = y # Training outputs\n",
    "        self.numberOfExamples = y.shape[0]  # Number of training examples\n",
    "        self.w_1 = np.ones((2, self.X.shape[1])) #(np.random.rand(2, 3) - 1) / 2  # Initialise weight matrix for layer 1\n",
    "        self.w_2 = np.ones((10,3)) #(np.random.rand(1, 3) - 1) / 2  # Initialise weight matrix for layer 2\n",
    "\n",
    "        # Error in each layer\n",
    "        self.sigma2 = np.zeros((2,1))\n",
    "        self.sigma3 = np.zeros((3,1))\n",
    "\n",
    "        #self.predictions = np.zeros((4,1))\n",
    "\n",
    "        # There is 2 input units in layer 1 and 2, and 1 output unit, excluding bias units.\n",
    "\n",
    "    def feedforward(self, x):\n",
    "\n",
    "        self.a_1 = x  # vector training example (layer 1 input)\n",
    "        print(\"a_1 \",self.a_1.shape)\n",
    "        self.z_2 = self.w_1 @ self.a_1\n",
    "        print(\"z_2 \",self.z_2)\n",
    "        self.a_2 = sigmoid(self.z_2)\n",
    "        print(\"a_2 \",self.a_2)\n",
    "        self.a_2 = np.vstack(([1], self.a_2))  # Add bias unit to a_2 for next layer computation\n",
    "        print(\"a_2 with bias \",self.a_2)\n",
    "        self.z_3 = self.w_2 @ self.a_2\n",
    "        print(\"z_3 \",self.z_3)\n",
    "        self.a_3 = sigmoid(self.z_3) # Output\n",
    "        print(\"a_3 \",self.a_3)\n",
    "        return self.a_3\n",
    "\n",
    "    def backprop(self):\n",
    "\n",
    "        # These are temporary variables used to compute self.D_1 and self.D_2\n",
    "        self.d_1 =  np.zeros(self.w_1.shape) \n",
    "        self.d_2 = np.zeros(self.w_2.shape)\n",
    "        \n",
    "        # These layers store the derivate of the cost with respect to the weights in each layer\n",
    "        self.D_1 = np.zeros(self.w_1.shape)\n",
    "        self.D_2 = np.zeros(self.w_2.shape)\n",
    "\n",
    "        for i in range(0,self.numberOfExamples):\n",
    "            print(\"Number of train = \",i)\n",
    "\n",
    "            self.feedforward(np.reshape(self.X[i, :], ((-1,1))))\n",
    "            #self.predictions[i,0] = self.a_3\n",
    "            #print(\"self.a_3 \", type(self.a_3))\n",
    "            #self.a_3 = self.a_3.reshape((self.a_3.shape[0],))\n",
    "            #y[i] = np.reshape(y[i], (y[i].shape, 1))\n",
    "            #y[i] = np.reshape(y[i], (-1, 1))\n",
    "            self.sigma3 = self.a_3.ravel() - y[i] #Calculate 'error' in layer 3\n",
    "            print(\"sigma3 \",self.sigma3)\n",
    "            print(\"y[i] \",y[i])\n",
    "            self.sigma2 = (self.w_2.T @ self.sigma3) * np.vstack(([0],sigmoid_derivative(self.z_2))) #Calculate 'error' in layer 2\n",
    "            '''We want the error for only 2 units, not for the bias unit. \n",
    "            However, in order to use the vectorised implementation we need the sigmoid derivative to be a 3 dimensional vector, so I added 0 as an element to the derivative.\n",
    "            This has no effect on the element-wise multiplication.'''\n",
    "            self.sigma2 = np.delete(self.sigma2, 0)  # Remove error associated to +1 bias unit as it has no error / output\n",
    "            self.sigma2 = np.reshape(self.sigma2, (-1, 1))\n",
    "            print(\"sigma2 \",self.sigma2) \n",
    "            print(\"check self.sigma3 \",self.sigma3.shape)\n",
    "            print(\"check self.a_2.T \",self.a_2.T.shape)\n",
    "            \n",
    "            # Adjust the temporary variables used to compute gradient of J\n",
    "            self.d_2 += self.sigma3 @ (self.a_2.T)\n",
    "            self.d_1 += self.sigma2 @ (self.a_1.T)\n",
    "\n",
    "        # Partial derivatives of cost function\n",
    "        self.D_2 = (1/self.numberOfExamples) * self.d_2\n",
    "        self.D_1 = (1/self.numberOfExamples) * self.d_1\n",
    "\n",
    "    def probs(self, X): #Function to generate the probabilites based on matrix of inputs\n",
    "        \n",
    "        probabilities = np.zeros((X.shape[0], 1))\n",
    "        for i in range(0, X.shape[0]):\n",
    "            test = np.reshape(X[i,:], (-1,1))\n",
    "            test = np.vstack(([1], test))\n",
    "            probabilities[i, 0] = self.feedforward(test)\n",
    "        return probabilities\n",
    "\n",
    "# Neural network object\n",
    "nn = NeuralNetwork(X,y)\n",
    "\n",
    "alpha = 1  # Learning Rate\n",
    "\n",
    "for i in range(0, 1): #Perform gradient descent\n",
    "    nn.backprop()\n",
    "\n",
    "    # Update weights\n",
    "    nn.w_1 += - alpha * nn.D_1\n",
    "    nn.w_2 += - alpha * nn.D_2\n",
    "\n",
    "    \n",
    "print(\"Finish training\")\n",
    "\n",
    "xx, yy = np.mgrid[-0.1:1.1:0.1, -0.1:1.1:0.1]\n",
    "\n",
    "grid = np.c_[xx.ravel(), yy.ravel()]\n",
    "\n",
    "# Find the probabilities for each combination of features\n",
    "\n",
    "probs = nn.probs(grid).reshape(xx.shape)\n",
    "\n",
    "f, ax = plt.subplots(figsize=(12, 10))\n",
    "\n",
    "# Create contour lines for each set of probabilities\n",
    "\n",
    "contour = ax.contourf(xx, yy, probs, 25, cmap=\"RdBu\", vmin=0, vmax=1)\n",
    "\n",
    "plt.title(\"x$_1$ XNOR x$_2$\")\n",
    "ax_c = f.colorbar(contour)\n",
    "ax_c.set_label(\"$P(y = 1 | X)$\")\n",
    "ax_c.set_ticks([0, .25, .5, .75, 1])\n",
    "\n",
    "# Plot training examples on figure\n",
    "\n",
    "ax.scatter(X[:,0], X[:, 1], c=y[:,0], s=50,\n",
    "           cmap=\"RdBu\", vmin=-.2, vmax=1.2,\n",
    "           edgecolor=\"white\", linewidth=1)\n",
    "\n",
    "ax.set(aspect=\"equal\",\n",
    "       xlabel=\"x$_1$\", ylabel=\"x$_2$\")\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
